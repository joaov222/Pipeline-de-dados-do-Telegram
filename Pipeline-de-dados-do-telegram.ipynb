{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"toc_visible":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Introdução do Projeto de ETL**\n\n\n\nOlá! Este notebook documenta detalhadamente todo o processo de criação de um pipeline de ETL (Extração, Transformação e Carregamento). O objetivo principal deste projeto é adquirir o máximo de experiência prática na construção de uma solução completa, explorando as diversas etapas e ferramentas envolvidas.  \n\n\n\nO pipeline criado neste projeto terá como objetivo extrair dados por meio de uma API de um grupo de chat no Telegram. Após a extração, esses dados serão processados e armazenados para futuras análises.\n\n\n\n---\n\n\n","metadata":{"id":"hnKrSeI5y-3V"}},{"cell_type":"markdown","source":"## **1. o que é ETL ?**\n\n\n\nO processo de **ETL (Extract, Transform, Load)** é um fluxo de trabalho utilizado para extrair dados de diversas fontes, transformá-los para atender a requisitos analíticos ou de armazenamento e carregá-los em um destino final, como um banco de dados ou data warehouse.\n\n\n\n1. **Extract (Extração):**\n\n   - Os dados são coletados de fontes diferentes, como APIs, bancos de dados ou arquivos.\n\n   - Nesta etapa, o principal desafio é lidar com formatos variados e garantir a captura eficiente dos dados.\n\n\n\n2. **Transform (Transformação):**\n\n   - Os dados extraídos são processados para atender a um formato consistente e utilizável.\n\n   - Isso pode incluir limpeza, normalização, agregação, ou a criação de novos campos derivados.\n\n\n\n3. **Load (Carregamento):**\n\n   - Os dados transformados são carregados para o destino final, como um repositório centralizado.\n\n   - O objetivo é disponibilizar os dados para análise, relatórios ou outras aplicações.\n\n\n\nEsse fluxo é essencial para consolidar informações e gerar insights em um ambiente corporativo ou analítico.\n","metadata":{"id":"xLvLHm2E5A5R"}},{"cell_type":"markdown","source":"---","metadata":{"id":"PtTS44aHAcRl"}},{"cell_type":"markdown","source":"## **2. Bot no Telegram**\n\n\n\nO Telegram permite a criação de **bots**, que são aplicações automatizadas capazes de interagir com os usuários através da sua API oficial. Os bots podem ser usados para uma ampla gama de funcionalidades, como:\n\n\n\n- **Envio e recebimento de mensagens.**\n\n- **Consulta de dados externos:** O bot pode consumir APIs e exibir informações, como o clima ou status de pedidos.\n\n- **Automação de tarefas:** Por exemplo, notificações automáticas, lembretes ou coleta de feedback.\n\n\n\n#### Etapas básicas para a criação de um bot para o projeto:\n\n1. **Criar um bot no Telegram:**\n\n   - Utilize o usuário **BotFather** no Telegram para registrar e configurar seu bot.\n\n   - Após o registro, o BotFather fornece um **token de acesso** usado para autenticação nas requisições da API.\n\n\n\n2. **Integração com a API:**\n\n   - O bot usa o **token** para acessar a API do Telegram e realizar operações, como enviar mensagens ou gerenciar conversas.\n\n   - aqui usaremos o bot como um leitor pondo como um Administrador de um grupo, assim poderemos extrair toda mensagen  mandada no grupo.\n\n\n\n3. **outros:**\n\n   - apos adicionar o bot ao grupo volte ao botfather e desligue a capacidade do bot entrar em novos grupos por segurança.\n\n\n\n4. **processo pratico**\n\n  - criação do bot\n\n  1. Abra o *chat* com o `BotFather`;\n\n  1. Digite `/newbot`;\n\n  1. Digite o nome do *bot*;\n\n  1. Digite o nome de usuário do *bot* (precisa terminar com sufixo `_bot`);\n\n  1. Salve o `token` de acesso a API HTTP em um <font color='red'>local seguro</font>.\n\n  ---\n\n  - Integração com a API:\n\n  1. Aperte o botão com o ícone de um lápis;\n\n  1. Selecione `New Group`;\n\n  1. Busque e selecione o *bot* recém criado pelo seu nome e confirme;\n\n  1. Digite o nome do grupo.\n\n  1. Abra o *chat* do grupo recém criado e Abra o perfil do grupo;\n\n  1. Aperte o botão com o ícone de um lápis;\n\n  1. Selecione Administrators;\n\n  1. Aperte o botão com o ícone de um usuário;\n\n  1. Selecione o *bot* e confirme;\n\n  ---\n\n  - outros\n\n  1. Abra o *chat* com o `BotFather`;\n\n  1. Digite `/mybots`;\n\n  1. Selecione o *bot* pelo seu nome de usuário;\n\n  1. Selecione `Bot Settings`;\n\n  1. Selecione `Allow Groups?`;\n\n  1. Selecione `Turn groups off`.\n\n\n\n\n","metadata":{"id":"itQUQ_ub5FWC"}},{"cell_type":"markdown","source":"## **3. Conceito basico**\n\nO conceito basico visa compreender o funcionamento da API para identificar meios de processar os dados de forma automatizada posteriormente. Por enquanto, serão realizados testes simples que servirão como base para as etapas futuras.","metadata":{"id":"GevGRbDy5zxU"}},{"cell_type":"code","source":"import json #json: Para trabalhar com dados no formato JSON.\n\nimport requests #requests: Para realizar requisições HTTP, útil para acessar APIs.\n\nimport pandas as pd #pandas: Para manipulação e análise de dados estruturados.\n\nfrom datetime import datetime #datetime: Para trabalhar com datas e horários.\n","metadata":{"id":"X2O_Beyi-Lw8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from getpass import getpass #getpass: Usado para ocultar a entrada de valores no terminal (como senhas ou tokens sensíveis).\n\n\n\napi_telegram = getpass()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Phqn6ZpG5u-L","outputId":"459d67c5-f70f-4050-b490-9c90e7f693bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"execution_count":null},{"cell_type":"markdown","source":"O valor inserido aqui é armazenado na variável api_telegram. Este token é necessário para autenticar as requisições à API do Telegram.","metadata":{"id":"k5JveyrWE7nr"}},{"cell_type":"code","source":"base_url = f'https://api.telegram.org/bot{api_telegram}'","metadata":{"id":"wqY5mwIW6hX7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a URL base para as chamadas à API do Telegram.","metadata":{"id":"wmg-EOL6FQC6"}},{"cell_type":"code","source":"# usando o getme\n\n\n\nresponse = requests.get(url=f'{base_url}/getMe')\n\n\n\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVn7eATi6hbM","outputId":"a3b7378c-56c4-4925-ce7d-484aed348258"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"ok\": true,\n","  \"result\": {\n","    \"id\": 7644877241,\n","    \"is_bot\": true,\n","    \"first_name\": \"0_bot\",\n","    \"username\": \"O_EBAC_bot\",\n","    \"can_join_groups\": false,\n","    \"can_read_all_group_messages\": false,\n","    \"supports_inline_queries\": false,\n","    \"can_connect_to_business\": false,\n","    \"has_main_web_app\": false\n","  }\n","}\n"]}],"execution_count":null},{"cell_type":"code","source":"# usando o getupdate\n\nresponse = requests.get(url=f'{base_url}/getUpdates')\n\n\n\nprint(json.dumps(json.loads(response.text), indent=2))\n\ndados=json.loads(response.text)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bQvdlg06her","outputId":"15558018-752e-4326-87fe-7b12f861d3a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"ok\": true,\n","  \"result\": [\n","    {\n","      \"update_id\": 484581844,\n","      \"message\": {\n","        \"message_id\": 86,\n","        \"from\": {\n","          \"id\": 6349852487,\n","          \"is_bot\": false,\n","          \"first_name\": \"Phan\",\n","          \"language_code\": \"pt-br\"\n","        },\n","        \"chat\": {\n","          \"id\": -1002482572030,\n","          \"title\": \"grupo chave\",\n","          \"type\": \"supergroup\"\n","        },\n","        \"date\": 1732728637,\n","        \"text\": \"olaaa\"\n","      }\n","    },\n","    {\n","      \"update_id\": 484581845,\n","      \"message\": {\n","        \"message_id\": 87,\n","        \"from\": {\n","          \"id\": 6349852487,\n","          \"is_bot\": false,\n","          \"first_name\": \"Phan\",\n","          \"language_code\": \"pt-br\"\n","        },\n","        \"chat\": {\n","          \"id\": -1002482572030,\n","          \"title\": \"grupo chave\",\n","          \"type\": \"supergroup\"\n","        },\n","        \"date\": 1732728641,\n","        \"text\": \"gg\"\n","      }\n","    }\n","  ]\n","}\n"]}],"execution_count":null},{"cell_type":"code","source":"dados=(dados['result'][0]['message'])","metadata":{"id":"BLkaqAn36hm0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndate = datetime.now().strftime('%Y-%m-%d')\n\ntimestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n\n\ndado_processado=dict()\n\n\n\nfor key , valor in dados.items():\n\n\n\n  if key == 'from':\n\n    for k, v in dados[key].items():\n\n        if k in ['id', 'is_bot', 'first_name']:\n\n            dado_processado[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n\n\n  elif key == 'chat':\n\n    for k , v in dados[key].items():\n\n      if k in [\"id\",\"type\"]:\n\n        dado_processado[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n\n\n      elif key in ['message_id', 'date', 'text']:\n\n        dado_processado[key] = [value]\n\n\n\nif not 'text' in dado_processado.keys():\n\n  dado_processado['text'] = [None]\n\n\n\ndado_processado['context_date'] = [date]\n\ndado_processado['context_timestamp'] = [timestamp]\n","metadata":{"id":"BY0ts36W9dH8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.DataFrame(dado_processado)\n\ndf","metadata":{"id":"oliIOogM9dUc","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"f33437aa-7856-4d55-92a9-eae1b74ec656"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      user_id  user_is_bot user_first_name        chat_id   chat_type  text  \\\n","0  6349852487        False            Phan -1002482572030  supergroup  None   \n","\n","  context_date    context_timestamp  \n","0   2024-11-27  2024-11-27 17:43:39  "],"text/html":["\n","  <div id=\"df-9c852502-f177-46b5-8e3a-c41612fecc28\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>user_is_bot</th>\n","      <th>user_first_name</th>\n","      <th>chat_id</th>\n","      <th>chat_type</th>\n","      <th>text</th>\n","      <th>context_date</th>\n","      <th>context_timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6349852487</td>\n","      <td>False</td>\n","      <td>Phan</td>\n","      <td>-1002482572030</td>\n","      <td>supergroup</td>\n","      <td>None</td>\n","      <td>2024-11-27</td>\n","      <td>2024-11-27 17:43:39</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c852502-f177-46b5-8e3a-c41612fecc28')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9c852502-f177-46b5-8e3a-c41612fecc28 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9c852502-f177-46b5-8e3a-c41612fecc28');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_acd683df-f35f-4141-a000-74c841cfd37c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_acd683df-f35f-4141-a000-74c841cfd37c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":19}],"execution_count":null},{"cell_type":"markdown","source":"## **4. Preparação no AWS**\n\n\n\nA AWS (Amazon Web Services) é uma plataforma robusta para construir soluções escaláveis e eficientes. Para este projeto, os seguintes serviços foram configurados:\n\n\n\n#### **1. Buckets no S3**\n\nOs **buckets** são repositórios de armazenamento no serviço Amazon S3 (Simple Storage Service). Eles são usados para armazenar e organizar arquivos, como os resultados de dados processados no ETL.\n\n\n\n- **Criação do bucket:**\n\n  - Acesse o console da AWS e navegue até o serviço S3.\n\n  - Crie um novo bucket, fornecendo um nome único e especificando a região onde será armazenado.\n\n  - Configure permissões de acesso apropriadas (por exemplo, somente leitura/escrita para usuários autorizados).\n\n\n\n- **Uso no ETL:**\n\n  - O bucket pode ser usado para armazenar dados extraídos ou transformados antes do carregamento final.\n\n- **buckets criados:**\n\n  - bucket_raw : contem os arquivos da operação de extração.\n\n  - bucket_enriched : contem os arquivos da operação de trasformação e load.\n\n---\n\n#### **2. API no AWS Gateway**\n\nO **API Gateway** é um serviço da AWS para criar e gerenciar APIs seguras e escaláveis.\n\n\n\n- **Objetivo:**\n\n  - Criar uma API que atue como interface para receber ou enviar dados ao longo do processo ETL.\n\n  - Por exemplo, um endpoint que o bot Telegram pode chamar para enviar ou obter informações.\n\n\n\n- **Configuração:**\n\n  1. Acesse o serviço e clique em *Create API* -> *REST API*.  \n\n  2. Insira um nome com o sufixo `-api`.  \n\n  3. Selecione *Actions* -> *Create Method* -> *POST*.  \n\n  4. Na tela de configuração, escolha *Integration type* como *Lambda Function*.  \n\n  5. Ative a opção *Use Lambda Proxy integration*.  \n\n  6. Localize a função do `AWS Lambda` pelo nome.  \n\n  7. Selecione *Actions* -> *Deploy API*.  \n\n  8. Escolha *New Stage* para *Deployment stage*.  \n\n  9. Adicione *dev* como `Stage name`.\n\n- copie o url para criação de um webhook\n\n---\n\n#### **3. Cronograma no AWS EventBridge**\n\nO **Amazon EventBridge** é um serviço usado para criar regras baseadas em eventos, como agendamentos.\n\n\n\n- **Objetivo:**\n\n  - Configurar um agendamento para automatizar o processo ETL.\n\n  - Por exemplo, executar o ETL diariamente às 00:00.\n\n\n\n- **Configuração:**\n\n  - Acesse o console do EventBridge.\n\n  - Crie uma nova regra com a opção \"Agenda\" (Schedule).\n\n  - Especifique a frequência usando expressões cron ou taxas simples (ex.: a cada 24 horas).\n\n  - Configure o destino da regra, como uma função Lambda que realiza o ETL.\n\n\n\n  expresão cron = 0 3 * * ? *\n\n\n\nOBS:Esta etapa deve ser realizada no final do projeto.\n","metadata":{"id":"mpq1euE0ugdi"}},{"cell_type":"markdown","source":"## **4.1 criação de um webhook**\n\n\n\nUm webhook é uma maneira de um sistema enviar notificações ou informações para outro sistema em tempo real, sem a necessidade de consultas frequentes (polling). Ele funciona como uma URL personalizada configurada para receber dados automaticamente sempre que um evento específico ocorre.","metadata":{"id":"PeT7BAbkIJgc"}},{"cell_type":"markdown","source":"Copie o a `url` gerada na variável `aws_api_gateway_url`.","metadata":{"id":"j0_uZ-IlJ5Q0"}},{"cell_type":"code","source":"aws_api_gateway_url = getpass()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvmJMfP8J4Rb","outputId":"5762303d-7f41-41ce-efbb-fd2ecf4d576e"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"execution_count":null},{"cell_type":"markdown","source":" - **setWebhook**","metadata":{"id":"Z0R9M-ZZV92P"}},{"cell_type":"markdown","source":"O método `setWebhook` configura o redirecionamento das mensagens captadas pelo *bot* para o endereço *web* do paramametro `url`.","metadata":{"id":"b_bTFFGdV92P"}},{"cell_type":"markdown","source":"> **Nota**: os métodos `getUpdates` e `setWebhook` são mutualmente exclusivos, ou seja, enquanto o *webhook* estiver ativo, o método `getUpdates` não funcionará. Para desativar o *webhook*, basta utilizar o método `deleteWebhook`.","metadata":{"id":"tSHPqn1wb_o-"}},{"cell_type":"code","source":"response = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\n\n\n\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"id":"dg4BCC44avB-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f11cb0c-d2a4-45a6-8890-683b0306f2be"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"ok\": true,\n","  \"result\": true,\n","  \"description\": \"Webhook was set\"\n","}\n"]}],"execution_count":null},{"cell_type":"markdown","source":" - **getWebhookInfo**","metadata":{"id":"sUmrHupw3kqX"}},{"cell_type":"markdown","source":"O método `getWebhookInfo` retorna as informações sobre o *webhook* configurado.","metadata":{"id":"T7cjJ3tL3xDV"}},{"cell_type":"code","source":"response = requests.get(url=f'{base_url}/getWebhookInfo')\n\n\n\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"id":"0D3O01qH3tVV"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" - **deleteWebhook**","metadata":{"id":"Y6Xv3mHuJaHb"}},{"cell_type":"markdown","source":"O método `deleteWebhook` serve para deletar o *Webhook*.","metadata":{"id":"eIxXotUtJed0"}},{"cell_type":"code","source":"\n\nresponse = requests.get(f'{base_url}/deleteWebhook')\n\n\n\n\n\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfIEyWEB9C7e","outputId":"17012129-13a8-4e40-97e0-217bdf3d0de5"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"ok\": true,\n","  \"result\": true,\n","  \"description\": \"Webhook was deleted\"\n","}\n"]}],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **5. Funções lambda**","metadata":{"id":"Q-QW4NNJGJkw"}},{"cell_type":"markdown","source":"### **5.1 Função Lambda no Processo Extract**\n\n\n\nA função Lambda no processo **Extract** desempenha o papel de **extrair dados** de fontes externas para iniciar o fluxo ETL. Sua principal funcionalidade é acessar uma ou mais fontes de dados, como APIs, bancos de dados ou sistemas de arquivos, e coletar os dados brutos para posterior processamento.\n\n\n\n#### **Funcionalidades da Função Lambda no Extract:**\n\n1. **Conexão com a Fonte de Dados:**\n\n   - Estabelece a conexão com a fonte externa (por exemplo, uma API REST).\n\n   - Envia requisições para obter os dados necessários, utilizando parâmetros apropriados.\n\n\n\n2. **Manipulação e Validação Inicial:**\n\n   - Verifica a integridade e o formato dos dados extraídos.\n\n   - Converte os dados para um formato estruturado, como JSON, se necessário.\n\n\n\n3. **Armazenamento Temporário:**\n\n   - Opcionalmente, salva os dados extraídos em um bucket S3 ou em outra solução de armazenamento intermediário para facilitar o processamento posterior.\n\n\n\n4. **Automação:**\n\n   - A função Lambda pode ser acionada automaticamente por eventos, como regras no Amazon EventBridge, para garantir que os dados sejam extraídos de forma periódica e sem intervenção manual.\n\n\n\nEssa etapa é crucial para coletar os dados brutos que serão transformados e carregados nas próximas fases do ETL, garantindo que a base de informações esteja disponível para análises posteriores.\n","metadata":{"id":"uOq-u0kF5NHr"}},{"cell_type":"code","source":"import os\n\nimport json\n\nimport logging\n\nfrom datetime import datetime, timezone , timedelta\n\n\n\nimport boto3\n\n\n\n\n\ndef lambda_handler(event: dict, context: dict) -> dict:\n\n\n\n  '''\n\n  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n\n  seu conteúdo se foi produzida em um determinado grupo e a escreve,\n\n  em seu formato original JSON, em um bucket do AWS S3.\n\n  '''\n\n\n\n  # vars de ambiente\n\n\n\n  BUCKET = os.environ['AWS_S3_BUCKET']\n\n  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n\n\n\n  # vars lógicas\n\n\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n\n  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n\n\n  filename = f'{timestamp}.json'\n\n\n\n  # código principal\n\n\n\n  client = boto3.client('s3')\n\n\n\n  try:\n\n\n\n    message = json.loads(event[\"body\"])\n\n    chat_id = message[\"message\"][\"chat\"][\"id\"]\n\n\n\n    if chat_id == TELEGRAM_CHAT_ID:\n\n\n\n      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n\n        json.dump(message, fp)\n\n\n\n      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n\n\n\n  except Exception as exc:\n\n      logging.error(msg=exc)\n\n      return dict(statusCode=\"500\")\n\n\n\n  else:\n\n      return dict(statusCode=\"200\")","metadata":{"id":"Nng8njAXq-4k"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"  \n\n\n\n### **5.2 Carregamento dos Dados Enriquecidos (Load)**  \n\n- Após a transformação, os dados compactados em Parquet são enviados para outro bucket S3, dedicado ao armazenamento de dados enriquecidos.  \n\n- O arquivo Parquet é organizado no bucket com base na data de processamento, permitindo uma estrutura hierárquica que facilita futuras consultas.  \n\n\n\n\n","metadata":{"id":"AHdHzlsekmj5"}},{"cell_type":"code","source":"import os\n\nimport json\n\nimport logging\n\nfrom datetime import datetime, timedelta, timezone\n\n\n\nimport boto3\n\nimport pyarrow as pa\n\nimport pyarrow.parquet as pq\n\n\n\n\n\ndef lambda_handler(event: dict, context: dict) -> bool:\n\n\n\n  '''\n\n  Diariamente é executado para compactar as diversas mensagensm, no formato\n\n  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único\n\n  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n\n  '''\n\n\n\n  # vars de ambiente\n\n\n\n  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n\n  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n\n\n\n  # vars lógicas\n\n\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n\n  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n\n\n  # código principal\n\n\n\n  table = None\n\n  client = boto3.client('s3')\n\n\n\n  try:\n\n\n\n      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n\n\n\n      for content in response['Contents']:\n\n\n\n        key = content['Key']\n\n        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n\n\n\n        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n\n\n\n          data = json.load(fp)\n\n          data = data[\"message\"]\n\n\n\n        parsed_data = parse_data(data=data)\n\n        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n\n\n\n        if table:\n\n\n\n          table = pa.concat_tables([table, iter_table])\n\n\n\n        else:\n\n\n\n          table = iter_table\n\n          iter_table = None\n\n\n\n      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n\n      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n\n\n\n      return True\n\n\n\n  except Exception as exc:\n\n      logging.error(msg=exc)\n\n      return False\n\n\n\n\n\n\n","metadata":{"id":"P4ROpPDE48o9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n### **5.3 Transformação dos Dados (Transform)**  \n\n- Cada arquivo JSON é processado localmente na Lambda para extrair e organizar as informações importantes das mensagens.  \n\n- A transformação é realizada através da função auxiliar `parse_data`, que filtra os campos essenciais (como ID do usuário, tipo de chat e texto da mensagem) e estrutura os dados para análise.  \n\n- Todos os dados processados são convertidos para o formato **Parquet**, utilizando a biblioteca **PyArrow**. Este formato é altamente eficiente para armazenamento e análise devido à sua compactação e estruturação columnar.","metadata":{"id":"D5duWYAryBvV"}},{"cell_type":"code","source":"#parte 2\n\n\n\ndef parse_data(data: dict) -> dict:\n\n\n\n  date = datetime.now().strftime('%Y-%m-%d')\n\n  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n\n\n  parsed_data = dict()\n\n\n\n  for key, value in data.items():\n\n\n\n      if key == 'from':\n\n          for k, v in data[key].items():\n\n              if k in ['id', 'is_bot', 'first_name']:\n\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n\n\n      elif key == 'chat':\n\n          for k, v in data[key].items():\n\n              if k in ['id', 'type']:\n\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n\n\n      elif key in ['message_id', 'date', 'text']:\n\n          parsed_data[key] = [value]\n\n\n\n  if not 'text' in parsed_data.keys():\n\n    parsed_data['text'] = [None]\n\n\n\n  return parsed_data","metadata":{"id":"n-fnJuQW4-BD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.4 Organização e Integração no Athena**  \n\n- Os dados no formato Parquet são consumidos por uma tabela externa configurada no **Amazon Athena**.  \n\n- A tabela é particionada por data, otimizando a performance das consultas SQL e reduzindo custos de análise.  \n\n- Para atualizar as partições após a adição dos novos dados, o comando `MSCK REPAIR TABLE` é executado automaticamente, integrando os dados ao esquema existente.  ","metadata":{"id":"ECZAx4moyIje"}},{"cell_type":"code","source":"#parte 3\n\n\n\n  from botocore.exceptions import ClientError\n\n\n\ndef lambda_handler(event, context) -> bool:\n\n\n\n\n\n  # -- setup\n\n\n\n\n\n  query = f\"\"\"\n\nCREATE EXTERNAL TABLE IF NOT EXISTS `telegram`(\n\n  `message_id` bigint,\n\n  `user_id` bigint,\n\n  `user_is_bot` boolean,\n\n  `user_first_name` string,\n\n  `chat_id` bigint,\n\n  `chat_type` string,\n\n  `text` string,\n\n  `date` bigint)\n\nPARTITIONED BY (\n\n  `context_date` date)\n\nROW FORMAT SERDE\n\n  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n\nSTORED AS INPUTFORMAT\n\n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n\nOUTPUTFORMAT\n\n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n\nLOCATION\n\n  's3://modulo42-ebac-etl-enriched/telegram/'\n\n \"\"\"\n\n\n\n\n\n  client = boto3.client('athena')\n\n\n\n  # -- create\n\n\n\n  try:\n\n    client.start_query_execution(\n\n      QueryString=query,\n\n      ResultConfiguration={'OutputLocation': 's3://ebac-joao-results-query/'}\n\n    )\n\n  except ClientError as exc:\n\n    raise exc\n\n\n\n  # -- update\n\n\n\n  try:\n\n    client.start_query_execution(\n\n      QueryString='MSCK REPAIR TABLE telegram',\n\n      ResultConfiguration={'OutputLocation': 's3://ebac-joao-results-query/'}\n\n    )\n\n  except ClientError as exc:\n\n    raise exc\n\n\n\n  return json.dumps(dict(status=True))","metadata":{"id":"320pLtHN48sb"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **6. Consultas no AWS Athena**","metadata":{"id":"OWIaL0eqkTXR"}},{"cell_type":"markdown","source":"- visão geral dos dados","metadata":{"id":"JabYW6qNp1bI"}},{"cell_type":"markdown","source":"```sql\n\nSELECT * FROM telegram limit 10;\n\n```\n\nResultado:\n\n\n\n| message_id | user_id    | user_is_bot | user_first_name | chat_id        | chat_type  | text                 | date       | context_date |\n|------------|------------|-------------|-----------------|----------------|------------|----------------------|------------|--------------|\n| 80         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | ola                  | 1732653315 | 2024-11-27   |\n| 81         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | around               | 1732725202 | 2024-11-27   |\n| 82         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | tempo                | 1732726362 | 2024-11-27   |\n| 83         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | cavalo               | 1732726365 | 2024-11-27   |\n| 84         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | animal               | 1732726367 | 2024-11-27   |\n| 85         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | espaço               | 1732726370 | 2024-11-27   |\n| 73         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | Arthur               | 1732645040 | 2024-11-26   |\n| 74         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | I                    | 1732645043 | 2024-11-26   |\n| 75         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | Have a god danm plan | 1732645060 | 2024-11-26   |\n| 76         | 6349852487 | false       | Phan            | -1002482572030 | supergroup | ARTHUR               | 1732645069 | 2024-11-26   |\n","metadata":{"id":"fGXRB3b8pr6o"}},{"cell_type":"markdown","source":"- Quantidade de mensagens por dia.","metadata":{"id":"VmC5D0hIk7il"}},{"cell_type":"markdown","source":"```sql\n\nSELECT\n\n  context_date,\n\n  count(1) AS \"message_amount\"\n\nFROM \"telegram\"\n\nGROUP BY context_date\n\nORDER BY context_date DESC\n\n```\n\nResultado:\n\n\n\n| context_date | message_amount |\n|--------------|----------------|\n| 2024-11-29   | 11             |\n| 2024-11-27   | 6              |\n| 2024-11-26   | 7              |\n","metadata":{"id":"H5jg8V2NkuLn"}},{"cell_type":"markdown","source":"- Quantidade de mensagens por usuário por dia.","metadata":{"id":"6FuUchi4k_Dk"}},{"cell_type":"markdown","source":"```sql\n\nSELECT\n\n  user_id,\n\n  user_first_name,\n\n  context_date,\n\n  count(1) AS \"message_amount\"\n\nFROM \"telegram\"\n\nGROUP BY\n\n  user_id,\n\n  user_first_name,\n\n  context_date\n\nORDER BY context_date DESC\n\n```\n\nResultado:\n\n\n\n| user_id    | user_first_name | context_date | message_amount |\n|------------|-----------------|--------------|----------------|\n| 6349852487 | Phan            | 2024-11-29   | 11             |\n| 6349852487 | Phan            | 2024-11-27   | 6              |\n| 6349852487 | Phan            | 2024-11-26   | 7              |\n","metadata":{"id":"yFKFbHqulCDP"}},{"cell_type":"markdown","source":"- Média do tamanho das mensagens por usuário por dia.","metadata":{"id":"zsyANjG8lOf8"}},{"cell_type":"markdown","source":"```sql\n\nSELECT\n\n  user_id,\n\n  user_first_name,\n\n  context_date,\n\n  CAST(AVG(length(text)) AS INT) AS \"average_message_length\"\n\nFROM \"telegram\"\n\nGROUP BY\n\n  user_id,\n\n  user_first_name,\n\n  context_date\n\nORDER BY context_date DESC\n\n```\n\nResultado:\n\n\n\n| user_id    | user_first_name | context_date | average_message_length |\n|------------|-----------------|--------------|------------------------|\n| 6349852487 | Phan            | 2024-11-29   | 7                      |\n| 6349852487 | Phan            | 2024-11-27   | 5                      |\n| 6349852487 | Phan            | 2024-11-26   | 14                     |\n","metadata":{"id":"0oZjoNkPlSHd"}},{"cell_type":"markdown","source":"- Quantidade de mensagens por hora por dia da semana por número da semana.","metadata":{"id":"1lrnb11eTpQ8"}},{"cell_type":"markdown","source":"```sql\n\nWITH\n\nparsed_date_cte AS (\n\n    SELECT\n\n        *,\n\n        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n\n    FROM \"telegram\"\n\n),\n\nhour_week_cte AS (\n\n    SELECT\n\n        *,\n\n        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n\n        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n\n        EXTRACT(week FROM parsed_date) AS parsed_date_weeknum\n\n    FROM parsed_date_cte\n\n)\n\nSELECT\n\n    parsed_date_hour,\n\n    parsed_date_weekday,\n\n    parsed_date_weeknum,\n\n    count(1) AS \"message_amount\"\n\nFROM hour_week_cte\n\nGROUP BY\n\n    parsed_date_hour,\n\n    parsed_date_weekday,\n\n    parsed_date_weeknum\n\nORDER BY\n\n    parsed_date_weeknum,\n\n    parsed_date_weekday\n\n```\n\nResultado:\n\n\n\n| parsed_date_hour | parsed_date_weekday | parsed_date_weeknum | message_amount |\n|------------------|---------------------|---------------------|----------------|\n| 18               | 2                   | 48                  | 7              |\n| 20               | 2                   | 48                  | 1              |\n| 16               | 3                   | 48                  | 5              |\n| 20               | 5                   | 48                  | 11             |\n","metadata":{"id":"7SJckV-nTpQ_"}}]}
